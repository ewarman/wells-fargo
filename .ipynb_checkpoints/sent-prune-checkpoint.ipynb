{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "with open('user-tweets.json') as file:\n",
    "    user_msgs = json.load(file)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read 400 labeled tweets\n",
      "Label distribution=[('N/A', 207), ('neg', 149), ('pos', 44)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "with open('sent-classified.json') as file:\n",
    "    labeled_msgs = json.load(file)\n",
    "file.close()\n",
    "    \n",
    "print('read %d labeled tweets' % len(labeled_msgs))\n",
    "\n",
    "label_map = {'0': 'N/A', '-': 'neg', '+': 'pos'}\n",
    "labels = ['N/A', 'neg', 'pos']\n",
    "\n",
    "count = 0\n",
    "for msg in labeled_msgs:\n",
    "    if msg['Sent'] is '':\n",
    "        msg['Sent'] = '0'\n",
    "    msg['Sent'] = label_map[msg['Sent']]\n",
    "        \n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(labels)\n",
    "y = label_encoder.transform([msg['Sent'] for msg in labeled_msgs])             \n",
    "print('Label distribution=%s' % Counter(msg['Sent'] for msg in labeled_msgs).most_common(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "def tokenize(text):\n",
    "    punc_re = '[' + re.escape(string.punctuation) + ']'\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'(.)\\1\\1\\1+', r'\\1', text)\n",
    "    text = re.sub(r'[0-9]', '9', text)\n",
    "    text = re.sub('bank(\\S+)', 'bankabcd', text)\n",
    "    text = re.sub('bank(\\S+)', 'bankabcd', text)\n",
    "    text = re.sub('#bank(\\S+)', '#bankabcd', text)\n",
    "    text = re.sub('twit_hndl_bank(\\S+)', 'twit_hndl_bankabcd', text)\n",
    "    toks = []\n",
    "    for tok in text.split():\n",
    "        tok = re.sub(r'^(' + punc_re + '+)', r'\\1 ', tok)\n",
    "        tok = re.sub(r'(' + punc_re + '+)$', r' \\1', tok)\n",
    "        for subtok in tok.split():\n",
    "            if re.search('\\w', subtok):\n",
    "                toks.append(subtok)\n",
    "    return toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorized 400 tweets. Found 1564 terms.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(decode_error='ignore', ngram_range=(1, 2), max_df=1., min_df=2,\n",
    "                             use_idf=True, tokenizer=tokenize, binary=False, norm='l2')\n",
    "X = vectorizer.fit_transform(msg['FullText'] for msg in labeled_msgs)\n",
    "print('Vectorized %d tweets. Found %d terms.' % (X.shape[0], X.shape[1]))\n",
    "features = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy=0.73500\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        N/A       0.73      0.88      0.80       207\n",
      "        neg       0.75      0.70      0.72       149\n",
      "        pos       0.70      0.16      0.26        44\n",
      "\n",
      "avg / total       0.73      0.73      0.71       400\n",
      "\n",
      "       N/A    neg    pos\n",
      "---  -----  -----  -----\n",
      "N/A    183     22      2\n",
      "neg     44    104      1\n",
      "pos     24     13      7\n",
      "\n",
      "CLASS 0\n",
      "name\t1.662\n",
      "internet\t1.138\n",
      "at\t1.067\n",
      "at bankabcd\t0.806\n",
      "for\t0.790\n",
      "\n",
      "CLASS 1\n",
      "i\t1.084\n",
      "why\t0.979\n",
      "atm\t0.881\n",
      "have\t0.863\n",
      "is\t0.855\n",
      "\n",
      "CLASS 2\n",
      "card\t1.667\n",
      "thanks\t1.448\n",
      "in bankabcd\t1.317\n",
      "my\t1.216\n",
      "much\t1.183\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_curve, precision_recall_fscore_support\n",
    "from tabulate import tabulate\n",
    "\n",
    "def confusion(truths, preds, labels):\n",
    "    m = confusion_matrix(truths, preds)\n",
    "    m = np.vstack((labels, m))\n",
    "    m = np.hstack((np.matrix([''] + list(labels)).T, m))\n",
    "    return tabulate(m.tolist(), headers='firstrow')\n",
    "\n",
    "def top_coef(clf, vocab, n=10):\n",
    "    if len(clf.classes_) == 2:\n",
    "        coefs = [clf.coef_[0], -clf.coef_[0]]\n",
    "    else:\n",
    "        coefs = clf.coef_\n",
    "    for li, label in enumerate(clf.classes_):\n",
    "        print('\\nCLASS %s' % label)\n",
    "        coef = coefs[li]\n",
    "        top_coef_ind = np.argsort(coef)[::-1][:n]\n",
    "        top_coef_terms = vocab[top_coef_ind]\n",
    "        top_coef = coef[top_coef_ind]\n",
    "        print('\\n'.join(['%s\\t%.3f' % (term, weight) for term, weight in zip(top_coef_terms, top_coef)]))\n",
    "\n",
    "def do_cv(X, y, labels, nfolds=10):\n",
    "    cv = KFold(len(y), nfolds, random_state=123456)\n",
    "    preds = []\n",
    "    truths = []\n",
    "    for train, test in cv:\n",
    "        clf = LogisticRegression(class_weight='balanced', solver='liblinear', intercept_scaling=.3)\n",
    "        clf.fit(X[train], y[train])\n",
    "        preds.extend(clf.predict(X[test]))\n",
    "        truths.extend(y[test])\n",
    "    print('accuracy=%.5f' % (accuracy_score(truths, preds)))\n",
    "    print(classification_report(truths, preds, target_names=labels))\n",
    "    print(confusion(truths, preds, labels))\n",
    "    clf = LogisticRegression(class_weight='balanced', solver='liblinear', intercept_scaling=.3)\n",
    "    clf.fit(X, y)\n",
    "    return clf, truths, preds\n",
    "clf, truths, preds = do_cv(X, y, label_encoder.classes_, 10)\n",
    "top_coef(clf, features, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.05  0.1   0.15  0.2   0.25  0.3   0.35  0.4   0.45  0.5   0.55  0.6\n",
      "  0.65  0.7   0.75  0.8   0.85  0.9   0.95  1.  ]\n",
      "label= N/A\n",
      "0.05 (0.71317829457364346, 0.88888888888888884, 0.79139784946236569, None)\n",
      "0.1 (0.71317829457364346, 0.88888888888888884, 0.79139784946236569, None)\n",
      "0.15 (0.71317829457364346, 0.88888888888888884, 0.79139784946236569, None)\n",
      "0.2 (0.71317829457364346, 0.88888888888888884, 0.79139784946236569, None)\n",
      "0.25 (0.71317829457364346, 0.88888888888888884, 0.79139784946236569, None)\n",
      "0.3 (0.71317829457364346, 0.88888888888888884, 0.79139784946236569, None)\n",
      "0.35 (0.71595330739299612, 0.88888888888888884, 0.79310344827586199, None)\n",
      "0.4 (0.76086956521739135, 0.84541062801932365, 0.8009153318077803, None)\n",
      "0.45 (0.80208333333333337, 0.7439613526570048, 0.77192982456140358, None)\n",
      "0.5 (0.88188976377952755, 0.54106280193236711, 0.6706586826347305, None)\n",
      "0.55 (0.94252873563218387, 0.39613526570048307, 0.55782312925170063, None)\n",
      "0.6 (0.95833333333333337, 0.22222222222222221, 0.36078431372549019, None)\n",
      "0.65 (1.0, 0.12077294685990338, 0.21551724137931033, None)\n",
      "0.7 (1.0, 0.033816425120772944, 0.065420560747663545, None)\n",
      "0.75 (1.0, 0.0096618357487922701, 0.019138755980861243, None)\n",
      "0.8 (0.0, 0.0, 0.0, None)\n",
      "0.85 (0.0, 0.0, 0.0, None)\n",
      "0.9 (0.0, 0.0, 0.0, None)\n",
      "0.95 (0.0, 0.0, 0.0, None)\n",
      "1.0 (0.0, 0.0, 0.0, None)\n",
      "label= neg\n",
      "0.05 (0.7407407407407407, 0.67114093959731547, 0.70422535211267601, None)\n",
      "0.1 (0.7407407407407407, 0.67114093959731547, 0.70422535211267601, None)\n",
      "0.15 (0.7407407407407407, 0.67114093959731547, 0.70422535211267601, None)\n",
      "0.2 (0.7407407407407407, 0.67114093959731547, 0.70422535211267601, None)\n",
      "0.25 (0.7407407407407407, 0.67114093959731547, 0.70422535211267601, None)\n",
      "0.3 (0.7407407407407407, 0.67114093959731547, 0.70422535211267601, None)\n",
      "0.35 (0.74626865671641796, 0.67114093959731547, 0.70671378091872794, None)\n",
      "0.4 (0.76470588235294112, 0.61073825503355705, 0.67910447761194037, None)\n",
      "0.45 (0.82666666666666666, 0.41610738255033558, 0.5535714285714286, None)\n",
      "0.5 (0.88888888888888884, 0.21476510067114093, 0.34594594594594597, None)\n",
      "0.55 (0.93333333333333335, 0.093959731543624164, 0.17073170731707316, None)\n",
      "0.6 (0.66666666666666663, 0.013422818791946308, 0.026315789473684213, None)\n",
      "0.65 (0.0, 0.0, 0.0, None)\n",
      "0.7 (0.0, 0.0, 0.0, None)\n",
      "0.75 (0.0, 0.0, 0.0, None)\n",
      "0.8 (0.0, 0.0, 0.0, None)\n",
      "0.85 (0.0, 0.0, 0.0, None)\n",
      "0.9 (0.0, 0.0, 0.0, None)\n",
      "0.95 (0.0, 0.0, 0.0, None)\n",
      "1.0 (0.0, 0.0, 0.0, None)\n",
      "label= pos\n",
      "0.05 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.1 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.15 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.2 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.25 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.3 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.35 (0.5714285714285714, 0.090909090909090912, 0.15686274509803921, None)\n",
      "0.4 (1.0, 0.045454545454545456, 0.086956521739130446, None)\n",
      "0.45 (1.0, 0.022727272727272728, 0.044444444444444446, None)\n",
      "0.5 (0.0, 0.0, 0.0, None)\n",
      "0.55 (0.0, 0.0, 0.0, None)\n",
      "0.6 (0.0, 0.0, 0.0, None)\n",
      "0.65 (0.0, 0.0, 0.0, None)\n",
      "0.7 (0.0, 0.0, 0.0, None)\n",
      "0.75 (0.0, 0.0, 0.0, None)\n",
      "0.8 (0.0, 0.0, 0.0, None)\n",
      "0.85 (0.0, 0.0, 0.0, None)\n",
      "0.9 (0.0, 0.0, 0.0, None)\n",
      "0.95 (0.0, 0.0, 0.0, None)\n",
      "1.0 (0.0, 0.0, 0.0, None)\n",
      "accuracy=0.720\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        N/A       0.71      0.89      0.79       207\n",
      "        neg       0.74      0.67      0.70       149\n",
      "        pos       0.57      0.09      0.16        44\n",
      "\n",
      "avg / total       0.71      0.72      0.69       400\n",
      "\n",
      "       N/A    neg    pos\n",
      "---  -----  -----  -----\n",
      "N/A    184     21      2\n",
      "neg     48    100      1\n",
      "pos     26     14      4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "def do_cv_thresh(X, y, labels, thresh=.5, nfolds=10):\n",
    "    cv = KFold(len(y), nfolds, random_state=123456)\n",
    "    preds = []\n",
    "    truths = []\n",
    "    probas = []\n",
    "    for train, test in cv:\n",
    "        clf = LogisticRegression(class_weight='balanced')\n",
    "        clf.fit(X[train], y[train])\n",
    "        proba = clf.predict_proba(X[test])\n",
    "        if len(probas) == 0:\n",
    "            probas = proba\n",
    "        else:\n",
    "            probas = np.vstack((probas, proba))\n",
    "        preds.extend(clf.predict(X[test]))\n",
    "        truths.extend(y[test])\n",
    "                       \n",
    "    # Now deterime best threshold for each class to maximize F1.\n",
    "    thresholds = np.arange(1,21) * .05\n",
    "    print(thresholds)\n",
    "    for i, l in enumerate(labels):\n",
    "        print('label=', l)\n",
    "        for thresh in thresholds:\n",
    "            newpreds = [1 if l2==i and probas[j][i] >= thresh else 0 for j, l2 in enumerate(preds)]\n",
    "            newtruths = [1 if t==i else 0 for t in truths]\n",
    "            #print Counter(newpreds)\n",
    "            print(thresh, precision_recall_fscore_support(newtruths, newpreds, average='binary'))\n",
    "    print('accuracy=%.3f' % (accuracy_score(truths, preds)))\n",
    "    print(classification_report(truths, preds, target_names=labels))\n",
    "    print(confusion(truths, preds, labels))\n",
    "    clf = LogisticRegression(class_weight='balanced')\n",
    "    clf.fit(X, y)\n",
    "    return clf, truths, preds\n",
    "\n",
    "clf, truths, preds = do_cv_thresh(X, y, label_encoder.classes_, .1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_raw = vectorizer.transform(msg['FullText'] for msg in user_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label distribution on messages: [(0, 60541), (1, 36772), (2, 2089)]\n",
      "0 is N/A, 1 is positive, 2 is negative\n"
     ]
    }
   ],
   "source": [
    "# Relabel all unlabeled tweets.\n",
    "probas_raw = clf.predict_proba(X_raw)\n",
    "preds_raw = clf.predict(X_raw)\n",
    "\n",
    "print('label distribution on messages: %s' % Counter(preds_raw).most_common(3))\n",
    "print('0 is N/A, 1 is positive, 2 is negative')\n",
    "for msg, pred in zip(user_msgs, preds_raw):\n",
    "    msg['Sent'] = labels[pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#write to file\n",
    "count = 0\n",
    "sent_msgs = []\n",
    "for msg in user_msgs:\n",
    "    if msg['Sent'] is 'pos' or msg['Sent'] is 'neg':\n",
    "        sent_msgs.append(msg)\n",
    "with open('sent-msgs.json', 'w') as file:\n",
    "    json.dump(sent_msgs, file) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
